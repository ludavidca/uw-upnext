{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mac = True\n",
    "\n",
    "if is_mac == True:\n",
    "    baseprompt_filepath = \"Data/basePrompt.in\"\n",
    "    instagram_data_filepath = \"Data/instagram_raw.csv\"\n",
    "    output_file = \"/Users/madhavmalik/VSC Projects/uw-upnext/uw-upnext/public/events.json\"\n",
    "    image_filepath = '/Users/madhavmalik/VSC Projects/uw-upnext/uw-upnext/public/InstagramImages/'\n",
    "else:\n",
    "    baseprompt_filepath = \"Data/basePrompt.in\"\n",
    "    instagram_data_filepath = \"Data/instagram_raw.csv\"\n",
    "    output_file = \"../public/events.json\"\n",
    "    image_filepath = \"../public/InstagramImages/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed row, error: 'image'\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "Failed row, error: 'image'\n",
      "success\n",
      "No street address 'streetAddress'\n",
      "Failed row, error: 'image'\n",
      "success\n",
      "No street address 'streetAddress'\n",
      "success\n",
      "No street address 'streetAddress'\n",
      "Failed row, error: 'image'\n",
      "No street address 'streetAddress'\n",
      "success\n",
      "success\n",
      "No street address 'location'\n",
      "success\n",
      "Failed row, error: 'image'\n",
      "success\n",
      "No street address 'location'\n",
      "success\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import time\n",
    "from requests.exceptions import RequestException\n",
    "from typing import List\n",
    "import json\n",
    "from together import Together\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "from enum import Enum, auto\n",
    "import re\n",
    "from pymongo import MongoClient, errors\n",
    "from pymongo.server_api import ServerApi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "basePrompt = open(baseprompt_filepath,\"r\", encoding = \"utf-8\").read()\n",
    "\n",
    "load_dotenv()\n",
    "togetherAPI = os.getenv('TOGETHER_API')\n",
    "#Updating WUSA Events\n",
    "webpage = requests.get(\"https://wusa.ca/events/\")\n",
    "jsonscript =str(webpage.content)\n",
    "isolatedinformation=jsonscript.split('<script type=\"application/ld+json\">')[1].split(\"</script>\")[0][4:-4].encode(\"utf16\", errors=\"surrogatepass\").decode(\"utf16\").encode().decode('unicode_escape')\n",
    "\n",
    "WUSAjson = json.loads(isolatedinformation.replace('&lt;p&gt;',\"\").replace(\"[&hellip;]&lt;/p&gt;\\\\\\\\n\",\"\"))\n",
    "\n",
    "wusaDf ={}\n",
    "postscolumns = ['account','date','caption',\"display_photo\",'event_details']\n",
    "wusaDf = pd.DataFrame(columns = postscolumns)\n",
    "\n",
    "import time\n",
    "\n",
    "time_now = int(time.time())\n",
    "for event in WUSAjson:\n",
    "    if int(datetime.datetime.fromisoformat(event[\"startDate\"]).timestamp()) >= time_now:\n",
    "        try: \n",
    "            location = event[\"location\"][\"address\"][\"streetAddress\"]\n",
    "        except Exception as err:\n",
    "            print(\"No street address\", str(err))\n",
    "            location = None\n",
    "        try:\n",
    "            new_row = pd.DataFrame({\n",
    "                    \"account\": [\"WUSA\"],\n",
    "                    \"date\": [time_now],\n",
    "                    \"caption\": str(event[\"description\"])+\" [For More Information, Click View Post] \",\n",
    "                    \"display_photo\": event[\"image\"],\n",
    "                    \"url\": [event['url']],\n",
    "                    \"likes\": [0],\n",
    "                    \"event_details\": [{\n",
    "                        \"is_event\": True,\n",
    "                        \"event_name\": event[\"name\"],\n",
    "                        \"event_description\": str(event[\"description\"])+\" ... \",\n",
    "                        \"categories\": [\"SOCIAL\"],\n",
    "                        \"start_time\": int(datetime.datetime.fromisoformat(event[\"startDate\"]).timestamp()),\n",
    "                        \"end_time\": int(datetime.datetime.fromisoformat(event[\"endDate\"]).timestamp()),\n",
    "                        \"location\": location,\n",
    "                    }]\n",
    "            })\n",
    "            wusaDf = pd.concat([wusaDf, new_row])\n",
    "            print(\"success\")\n",
    "        except Exception as error:\n",
    "            print(\"Failed row, error:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents removed: 22\n",
      "Inserted document ID: 6726ea5e7d33b8a433a8fe39\n",
      "Inserted document ID: 6726ea5f7d33b8a433a8fe3a\n",
      "Inserted document ID: 6726ea607d33b8a433a8fe3b\n",
      "Inserted document ID: 6726ea617d33b8a433a8fe3c\n",
      "Inserted document ID: 6726ea627d33b8a433a8fe3d\n",
      "Inserted document ID: 6726ea627d33b8a433a8fe3e\n",
      "Inserted document ID: 6726ea637d33b8a433a8fe3f\n",
      "Inserted document ID: 6726ea647d33b8a433a8fe40\n",
      "Inserted document ID: 6726ea657d33b8a433a8fe41\n",
      "Inserted document ID: 6726ea667d33b8a433a8fe42\n",
      "Inserted document ID: 6726ea667d33b8a433a8fe43\n",
      "Inserted document ID: 6726ea677d33b8a433a8fe44\n",
      "Inserted document ID: 6726ea687d33b8a433a8fe45\n",
      "Inserted document ID: 6726ea697d33b8a433a8fe46\n",
      "Inserted document ID: 6726ea6a7d33b8a433a8fe47\n",
      "Inserted document ID: 6726ea6b7d33b8a433a8fe48\n",
      "Inserted document ID: 6726ea6b7d33b8a433a8fe49\n",
      "Inserted document ID: 6726ea6c7d33b8a433a8fe4a\n",
      "Inserted document ID: 6726ea6d7d33b8a433a8fe4b\n",
      "Inserted document ID: 6726ea6e7d33b8a433a8fe4c\n",
      "Inserted document ID: 6726ea6e7d33b8a433a8fe4d\n",
      "Inserted document ID: 6726ea6f7d33b8a433a8fe4e\n",
      "All inserted document IDs: [ObjectId('6726ea5e7d33b8a433a8fe39'), ObjectId('6726ea5f7d33b8a433a8fe3a'), ObjectId('6726ea607d33b8a433a8fe3b'), ObjectId('6726ea617d33b8a433a8fe3c'), ObjectId('6726ea627d33b8a433a8fe3d'), ObjectId('6726ea627d33b8a433a8fe3e'), ObjectId('6726ea637d33b8a433a8fe3f'), ObjectId('6726ea647d33b8a433a8fe40'), ObjectId('6726ea657d33b8a433a8fe41'), ObjectId('6726ea667d33b8a433a8fe42'), ObjectId('6726ea667d33b8a433a8fe43'), ObjectId('6726ea677d33b8a433a8fe44'), ObjectId('6726ea687d33b8a433a8fe45'), ObjectId('6726ea697d33b8a433a8fe46'), ObjectId('6726ea6a7d33b8a433a8fe47'), ObjectId('6726ea6b7d33b8a433a8fe48'), ObjectId('6726ea6b7d33b8a433a8fe49'), ObjectId('6726ea6c7d33b8a433a8fe4a'), ObjectId('6726ea6d7d33b8a433a8fe4b'), ObjectId('6726ea6e7d33b8a433a8fe4c'), ObjectId('6726ea6e7d33b8a433a8fe4d'), ObjectId('6726ea6f7d33b8a433a8fe4e')]\n"
     ]
    }
   ],
   "source": [
    "together_api_key = os.getenv('TOGETHER_API')\n",
    "\n",
    "\n",
    "#code for embedding\n",
    "embedding_model_string = 'WhereIsAI/UAE-Large-V1' # model API string from Together.\n",
    "\n",
    "def generate_embedding(input_texts: List[str], model_api_string: str) -> List[List[float]]:\n",
    "  together_client = Together(api_key=together_api_key)\n",
    "  outputs = together_client.embeddings.create(\n",
    "      input=input_texts,\n",
    "      model=model_api_string,\n",
    "  )\n",
    "  return [x.embedding for x in outputs.data]\n",
    "\n",
    "insertObjectIds = []\n",
    "\n",
    "# Set up MongoDB client\n",
    "uri = os.getenv('DATABASE_URI')\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client['Instagram']\n",
    "collection = db[\"Events\"]\n",
    "\n",
    "# Remove all documents with 'account': \"WUSA\"\n",
    "try:\n",
    "    result = collection.delete_many({'account': \"WUSA\"})\n",
    "    print(f\"Documents removed: {result.deleted_count}\")\n",
    "except errors.PyMongoError as e:\n",
    "    print(f\"Error deleting documents: {e}\")\n",
    "\n",
    "# Check and remove '_id' column if present\n",
    "if '_id' in wusaDf.columns:\n",
    "    print(\"DataFrame contains an '_id' column. It will be removed to prevent duplication.\")\n",
    "    wusaDf = wusaDf.drop(columns=['_id'])\n",
    "\n",
    "for index, row in wusaDf.iterrows():\n",
    "    # Construct the info string\n",
    "    info = f'\"id\": \"{int(index)}\"|* \"account\": \"{row[\"account\"]}\"|* \"date\": \"{row[\"date\"]}\"|* \"caption\": \"{row[\"caption\"]}\"|*'\n",
    "    embeddedtext = ',\\n'.join(x for x in info.replace('\\n','\\\\n').split('|*')) \n",
    "\n",
    "    # Create the document dictionary\n",
    "    row_dict = {column: row[column] for column in wusaDf.columns.tolist()}\n",
    "    \n",
    "    # Add the embedded field\n",
    "    row_dict[\"embedded\"] = generate_embedding([embeddedtext], embedding_model_string)\n",
    "    \n",
    "    # Remove '_id' if present to let MongoDB generate it\n",
    "    row_dict.pop('_id', None)\n",
    "    \n",
    "    try:\n",
    "        result = collection.insert_one(row_dict)\n",
    "        print(f\"Inserted document ID: {result.inserted_id}\")\n",
    "        insertObjectIds.append(result.inserted_id)\n",
    "    except errors.DuplicateKeyError as e:\n",
    "        print(f\"DuplicateKeyError: {e}. Document skipped.\")\n",
    "    except errors.PyMongoError as e:\n",
    "        print(f\"An error occurred: {e}. Document skipped.\")\n",
    "    \n",
    "    time.sleep(0.5)  # Adjust or remove delay as needed\n",
    "\n",
    "# Optionally, print all inserted ObjectIds\n",
    "print(f\"All inserted document IDs: {insertObjectIds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "No\n",
      "No\n",
      "Yes\n",
      "No\n",
      "Yes\n",
      "Yes\n",
      "No\n",
      "No\n",
      "Yes\n",
      "No\n",
      "No\n",
      "No\n",
      "Yes\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "#Validating if it is an event\n",
    "load_dotenv()\n",
    "togetherAPI = os.getenv('TOGETHER_API')\n",
    "client = Together(api_key=togetherAPI)\n",
    "\n",
    "postsDf = pd.read_csv(instagram_data_filepath).replace('\"','', regex=True)\n",
    "postsDf[\"is_event\"] = pd.NA\n",
    "postsDf[\"processed_json\"]=pd.NA\n",
    "\n",
    "def check_string(input_string):\n",
    "    if any(word in input_string for word in ['yes', 'Yes', 'True', 'true']):\n",
    "        return True\n",
    "    elif any(word in input_string for word in ['no', 'No', 'False', 'false']):\n",
    "        return False\n",
    "    else:\n",
    "        return False  # This handles cases where none of the words are found\n",
    "\n",
    "\n",
    "cnt=0\n",
    "for index, row in postsDf.iterrows():\n",
    "    currentjson = f\"'account': '{row['account']}'; 'caption': '{row['caption']}'; 'photo_caption': '{row['accessibility_caption']}; 'date_posted_on_instagram: {row['date']}'\"\n",
    "    postsDf.at[index, \"processed_json\"] = currentjson\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f'Does the following instagram post contain a club event with a specified time. RETURN Yes or No only: {currentjson}'}],\n",
    "        max_tokens=2\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    is_event = check_string(response.choices[0].message.content)\n",
    "    postsDf.at[index, \"is_event\"] = is_event\n",
    "    time.sleep(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to Aid in LLM JSON data extraction\n",
    "\n",
    "\n",
    "client = Together(api_key=togetherAPI)\n",
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Unicode ranges for emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "class Category(Enum):\n",
    "    TECH = auto()\n",
    "    DESIGN = auto()\n",
    "    SOCIAL = auto()\n",
    "    ENTERTAINMENT = auto()\n",
    "    CULTURE = auto()\n",
    "    SPORTS = auto()\n",
    "    NETWORKING = auto()\n",
    "    GAMING = auto()\n",
    "\n",
    "class Event(BaseModel):\n",
    "    is_event: bool = Field(description=\"Whether the post contains an event\")\n",
    "    event_name: str = Field(description=\"The Name of the Event\")\n",
    "    event_description: str = Field(description='Concise 20 word summary of the event without time or location')\n",
    "    event_categories: list[str] = Field(description='Categorize the Event into at least one or more of the following: TECH, DESIGN, SOCIAL, MUSIC, CULTURE, SPORTS, NETWORK, GAMING')\n",
    "    start_time: str = Field(description=\"The Start time of Event in the format: yyyy-mm-ddTHH:MM:SS+00:00\")\n",
    "    end_time: str = Field(description=\"The End time of Event in the format: yyyy-mm-ddTHH:MM:SS+00:00\")\n",
    "    location: str = Field(description= \"The location of event\")\n",
    "\n",
    "def return_event_details(inputJson : str):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    model = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    response_format={\"type\": \"json_object\", \"schema\": Event.model_json_schema()},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": basePrompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\n\\n Input \" + remove_emojis(inputJson) + \"\\n\\n\" + \"Output\",\n",
    "        },\n",
    "    ])\n",
    "    \n",
    "    created_event = json.loads(chat_completion.choices[0].message.content)\n",
    "    return created_event\n",
    "\n",
    "def extract_details_with_error_handling(inputJson, index):\n",
    "        try: \n",
    "            created_event = return_event_details(inputJson)\n",
    "            return created_event\n",
    "        except Exception as err:\n",
    "            print(str(err))\n",
    "            return {'is_event': False, 'event_name': None, 'start_time': None, 'end_time': None, 'location': None}\n",
    "\n",
    "postsDf[\"event_details\"] = pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def download_image(url: str, save_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Download an image from a URL and save it to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL of the image to download\n",
    "        save_path (str): The path where the image should be saved\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to Path object for better path handling\n",
    "        save_path = Path(save_path)\n",
    "        \n",
    "        # Ensure the filename has a valid extension\n",
    "        if not save_path.suffix:\n",
    "            save_path = save_path.with_suffix('.jpg')\n",
    "            \n",
    "        # Create the directory if it doesn't exist\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Check write permissions for the directory\n",
    "        if not os.access(str(save_path.parent), os.W_OK):\n",
    "            print(f\"Error: No write permission for directory: {save_path.parent}\")\n",
    "            return False\n",
    "            \n",
    "        # Check if file already exists\n",
    "        if save_path.exists():\n",
    "            print(f\"Warning: File already exists at {save_path}\")\n",
    "            # You might want to implement a strategy here (skip, overwrite, rename)\n",
    "            return False\n",
    "            \n",
    "        # Download the image\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading image: {e}\")\n",
    "            return False\n",
    "            \n",
    "        # Verify the content type is an image\n",
    "        content_type = response.headers.get('content-type', '')\n",
    "        if not content_type.startswith('image/'):\n",
    "            print(f\"Error: URL does not point to an image (content-type: {content_type})\")\n",
    "            return False\n",
    "            \n",
    "        # Save the image\n",
    "        try:\n",
    "            save_path.write_bytes(response.content)\n",
    "            print(f\"Image successfully downloaded to {save_path}\")\n",
    "            return True\n",
    "        except IOError as e:\n",
    "            print(f\"Error saving image: {e}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 no event detected\n",
      "1 no event detected\n",
      "2 no event detected\n",
      "3 {'is_event': True, 'event_name': 'Case 101', 'event_description': 'Master tackling cases with case competition and interview expertise', 'event_categories': ['TECH', 'DESIGN', 'NETWORK', 'CULTURE'], 'start_time': '2024-09-19T19:00:00+00:00', 'end_time': '2024-09-19T20:30:00+00:00', 'location': 'STC 0040'}\n",
      "Image successfully downloaded to public/InstagramImages/C_-9xjnA411.jpg\n",
      "4 no event detected\n",
      "5 {'is_event': True, 'event_name': 'Cansbridge Fellowship Info Session', 'event_description': 'Cansbridge Fellowship info session with Tech+ UW', 'event_categories': ['TECH'], 'start_time': '2024-10-01T17:30:00+00:00', 'end_time': '2024-10-01T19:00:00+00:00', 'location': 'University of Waterloo, Ideas Clinic in E7'}\n",
      "Image successfully downloaded to public/InstagramImages/DAaJUJpAgVz.jpg\n",
      "6 {'is_event': True, 'event_name': 'Co-op Bootcamp Kick-off', 'event_description': 'Learn about co-op at UW and get resume reviewed', 'event_categories': ['TECH'], 'start_time': '2024-09-19T19:00:00+00:00', 'end_time': '2024-09-19T21:00:00+00:00', 'location': 'DC 1302'}\n",
      "Image successfully downloaded to public/InstagramImages/DAEj4l3y5Ga.jpg\n",
      "7 no event detected\n",
      "8 no event detected\n",
      "9 {'is_event': True, 'event_name': 'Case 101', 'event_description': 'Master case competitions, case interviews, and business problems', 'event_categories': ['TECH'], 'start_time': '2024-09-19T19:00:00+00:00', 'end_time': '2024-09-19T20:30:00+00:00', 'location': 'STC 0040'}\n",
      "Warning: File already exists at public/InstagramImages/C_-9xjnA411.jpg\n",
      "10 no event detected\n",
      "11 no event detected\n",
      "12 no event detected\n",
      "13 {'is_event': False, 'event_name': '', 'event_description': '', 'event_categories': [], 'start_time': '', 'end_time': '', 'location': ''}\n",
      "Image successfully downloaded to public/InstagramImages/C_hWH4eA3AX.jpg\n",
      "14 no event detected\n",
      "15 no event detected\n",
      "16 no event detected\n",
      "17 no event detected\n",
      "18 no event detected\n"
     ]
    }
   ],
   "source": [
    "for index, row in postsDf.iterrows():\n",
    "    if postsDf.at[index, \"is_event\"]== True:\n",
    "        event_details = return_event_details(str(postsDf.at[index, \"processed_json\"]))\n",
    "        print(index, event_details)\n",
    "        if event_details[\"event_name\"] == None or event_details[\"start_time\"] == None or event_details[\"end_time\"] == None:\n",
    "            postsDf.at[index, \"is_event\"] = False\n",
    "            postsDf.at[index, \"event_details\"] = None\n",
    "        else:\n",
    "            postsDf.at[index, \"event_details\"] = event_details\n",
    "            imageurl = row[\"display_photo\"]\n",
    "            postID = row[\"url\"]\n",
    "            filepath = image_filepath + postID + \".jpg\"\n",
    "            download_image(imageurl, filepath)\n",
    "    else: print(index, \"no event detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1726786800.0 1726792200.0\n",
      "1727818200.0 1727823600.0\n",
      "1726786800.0 1726794000.0\n",
      "1726786800.0 1726792200.0\n",
      "13 Start failed \n",
      "1726786800.0 1726792200.0\n",
      "Inserted document ID: 6726ea8f7d33b8a433a8fe50\n",
      "Inserted document ID: 6726ea917d33b8a433a8fe51\n",
      "Inserted document ID: 6726ea927d33b8a433a8fe52\n",
      "Inserted document ID: 6726ea937d33b8a433a8fe53\n"
     ]
    }
   ],
   "source": [
    "#RAG Processing\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "uri = os.getenv('DATABASE_URI')\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client['Instagram']\n",
    "collection = db[\"Events\"]\n",
    "\n",
    "#time conversion and edit formats\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "postsDf.reset_index(drop=True)\n",
    "postsDf = postsDf.fillna(value=\"None\")\n",
    "postsDf.drop(postsDf.columns[postsDf.columns.str.contains(\n",
    "    'unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "for index, row in postsDf.iterrows():\n",
    "    if row[\"is_event\"] == True:\n",
    "      row_dict = row[\"event_details\"]\n",
    "      try:\n",
    "        conStart = datetime.fromisoformat(row_dict[\"start_time\"])\n",
    "        unixStart = time.mktime(conStart.timetuple()) \n",
    "        try:\n",
    "          conEnd = datetime.fromisoformat(row_dict[\"end_time\"])\n",
    "          unixEnd = time.mktime(conEnd.timetuple())\n",
    "        except:\n",
    "          unixEnd = None\n",
    "        row_dict[\"start_time\"]=unixStart\n",
    "        row_dict[\"end_time\"]=unixEnd\n",
    "      except:\n",
    "        postsDf.at[index, \"is_event\"] = False\n",
    "        err = f'Start failed {row_dict[\"start_time\"]}'\n",
    "        print(index, err)\n",
    "      postsDf.at[index, \"event_details\"] = row_dict\n",
    "      print(unixStart,unixEnd)\n",
    "\n",
    "together_api_key = os.getenv('TOGETHER_API')\n",
    "\n",
    "\n",
    "#code for embedding\n",
    "embedding_model_string = 'WhereIsAI/UAE-Large-V1' # model API string from Together.\n",
    "\n",
    "def generate_embedding(input_texts: List[str], model_api_string: str) -> List[List[float]]:\n",
    "  together_client = Together(api_key=together_api_key)\n",
    "  outputs = together_client.embeddings.create(\n",
    "      input=input_texts,\n",
    "      model=model_api_string,\n",
    "  )\n",
    "  return [x.embedding for x in outputs.data]\n",
    "\n",
    "for index, row in postsDf.iterrows():\n",
    "    if row[\"is_event\"] == True:\n",
    "      row_dict = {}\n",
    "      for column in postsDf.columns.tolist():\n",
    "        if column in ['account','date','caption','accessibility_caption','url','likes','display_photo']:\n",
    "          row_dict[column] = row[column]\n",
    "      row_dict[\"embedded\"] = generate_embedding([row[\"processed_json\"]], embedding_model_string)  \n",
    "      row_dict[\"event_details\"] = row[\"event_details\"]\n",
    "      result = collection.insert_one(row_dict)\n",
    "      print(f\"Inserted document ID: {result.inserted_id}\")\n",
    "      time.sleep(1)\n",
    "\n",
    "#Updating Events.json\n",
    "\n",
    "def download_future_events_to_json(output_file):\n",
    "    # Get current Unix timestamp\n",
    "    current_timestamp = int(time.time())\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    load_dotenv()\n",
    "    uri = os.getenv('DATABASE_URI')\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    db = client['Instagram']\n",
    "    collection = db[\"Events\"]\n",
    "\n",
    "    # Query for future events\n",
    "    query = {}\n",
    "    future_events = list(collection.find(query))\n",
    "\n",
    "    # Convert ObjectId to string for JSON serialization\n",
    "    for event in future_events:\n",
    "        event['_id'] = str(event['_id'])\n",
    "\n",
    "    # Write to JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(future_events, f, indent=2)\n",
    "\n",
    "    # Close the MongoDB connection\n",
    "    client.close()\n",
    "\n",
    "    return future_events\n",
    "\n",
    "\n",
    "future_events = download_future_events_to_json(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
