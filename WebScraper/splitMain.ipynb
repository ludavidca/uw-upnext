{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_mac = False\n",
    "\n",
    "if is_mac == True:\n",
    "    baseprompt_filepath = \"Data/basePrompt.in\"\n",
    "    instagram_data_filepath = \"Data/instagram_raw.csv\"\n",
    "    output_file = \"./public/events.json\"\n",
    "    image_filepath = './public/InstagramImages/'\n",
    "else:\n",
    "    baseprompt_filepath = \"Data/basePrompt.in\"\n",
    "    instagram_data_filepath = \"Data/instagram_raw.csv\"\n",
    "    output_file = \"../public/events.json\"\n",
    "    image_filepath = \"../public/InstagramImages/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed row, error: 'image'\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "Failed row, error: 'image'\n",
      "success\n",
      "No street address 'streetAddress'\n",
      "Failed row, error: 'image'\n",
      "success\n",
      "No street address 'streetAddress'\n",
      "success\n",
      "No street address 'streetAddress'\n",
      "Failed row, error: 'image'\n",
      "No street address 'streetAddress'\n",
      "success\n",
      "success\n",
      "No street address 'location'\n",
      "success\n",
      "Failed row, error: 'image'\n",
      "success\n",
      "No street address 'location'\n",
      "success\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import time\n",
    "from requests.exceptions import RequestException\n",
    "from typing import List\n",
    "import json\n",
    "from together import Together\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "from enum import Enum, auto\n",
    "import re\n",
    "from pymongo import MongoClient, errors\n",
    "from pymongo.server_api import ServerApi\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "basePrompt = open(baseprompt_filepath,\"r\", encoding = \"utf-8\").read()\n",
    "\n",
    "load_dotenv()\n",
    "togetherAPI = os.getenv('TOGETHER_API')\n",
    "#Updating WUSA Events\n",
    "webpage = requests.get(\"https://wusa.ca/events/\")\n",
    "jsonscript =str(webpage.content)\n",
    "isolatedinformation=jsonscript.split('<script type=\"application/ld+json\">')[1].split(\"</script>\")[0][4:-4].encode(\"utf16\", errors=\"surrogatepass\").decode(\"utf16\").encode().decode('unicode_escape')\n",
    "\n",
    "WUSAjson = json.loads(isolatedinformation.replace('&lt;p&gt;',\"\").replace(\"[&hellip;]&lt;/p&gt;\\\\\\\\n\",\"\"))\n",
    "\n",
    "wusaDf ={}\n",
    "postscolumns = ['account','date','caption',\"display_photo\",'event_details']\n",
    "wusaDf = pd.DataFrame(columns = postscolumns)\n",
    "\n",
    "import time\n",
    "\n",
    "time_now = int(time.time())\n",
    "for event in WUSAjson:\n",
    "    if int(datetime.datetime.fromisoformat(event[\"startDate\"]).timestamp()) >= time_now:\n",
    "        try: \n",
    "            location = event[\"location\"][\"address\"][\"streetAddress\"]\n",
    "        except Exception as err:\n",
    "            print(\"No street address\", str(err))\n",
    "            location = None\n",
    "        try:\n",
    "            new_row = pd.DataFrame({\n",
    "                    \"account\": [\"WUSA\"],\n",
    "                    \"date\": [time_now],\n",
    "                    \"caption\": str(event[\"description\"])+\" [For More Information, Click View Post] \",\n",
    "                    \"display_photo\": event[\"image\"],\n",
    "                    \"url\": [event['url']],\n",
    "                    \"likes\": [0],\n",
    "                    \"event_details\": [{\n",
    "                        \"is_event\": True,\n",
    "                        \"event_name\": event[\"name\"],\n",
    "                        \"event_description\": str(event[\"description\"])+\" ... \",\n",
    "                        \"categories\": [\"SOCIAL\"],\n",
    "                        \"start_time\": int(datetime.datetime.fromisoformat(event[\"startDate\"]).timestamp()),\n",
    "                        \"end_time\": int(datetime.datetime.fromisoformat(event[\"endDate\"]).timestamp()),\n",
    "                        \"location\": location,\n",
    "                    }]\n",
    "            })\n",
    "            wusaDf = pd.concat([wusaDf, new_row])\n",
    "            print(\"success\")\n",
    "        except Exception as error:\n",
    "            print(\"Failed row, error:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents removed: 21\n",
      "Inserted document ID: 6726cbf9fa90a11c6574e340\n",
      "Inserted document ID: 6726cbfafa90a11c6574e341\n",
      "Inserted document ID: 6726cbfbfa90a11c6574e342\n",
      "Inserted document ID: 6726cbfbfa90a11c6574e343\n",
      "Inserted document ID: 6726cbfcfa90a11c6574e344\n",
      "Inserted document ID: 6726cbfdfa90a11c6574e345\n",
      "Inserted document ID: 6726cbfefa90a11c6574e346\n",
      "Inserted document ID: 6726cbfffa90a11c6574e347\n",
      "Inserted document ID: 6726cc00fa90a11c6574e348\n",
      "Inserted document ID: 6726cc00fa90a11c6574e349\n",
      "Inserted document ID: 6726cc01fa90a11c6574e34a\n",
      "Inserted document ID: 6726cc02fa90a11c6574e34b\n",
      "Inserted document ID: 6726cc03fa90a11c6574e34c\n",
      "Inserted document ID: 6726cc04fa90a11c6574e34d\n",
      "Inserted document ID: 6726cc04fa90a11c6574e34e\n",
      "Inserted document ID: 6726cc05fa90a11c6574e34f\n",
      "Inserted document ID: 6726cc06fa90a11c6574e350\n",
      "Inserted document ID: 6726cc07fa90a11c6574e351\n",
      "Inserted document ID: 6726cc08fa90a11c6574e352\n",
      "Inserted document ID: 6726cc09fa90a11c6574e353\n",
      "Inserted document ID: 6726cc09fa90a11c6574e354\n",
      "All inserted document IDs: [ObjectId('6726cbf9fa90a11c6574e340'), ObjectId('6726cbfafa90a11c6574e341'), ObjectId('6726cbfbfa90a11c6574e342'), ObjectId('6726cbfbfa90a11c6574e343'), ObjectId('6726cbfcfa90a11c6574e344'), ObjectId('6726cbfdfa90a11c6574e345'), ObjectId('6726cbfefa90a11c6574e346'), ObjectId('6726cbfffa90a11c6574e347'), ObjectId('6726cc00fa90a11c6574e348'), ObjectId('6726cc00fa90a11c6574e349'), ObjectId('6726cc01fa90a11c6574e34a'), ObjectId('6726cc02fa90a11c6574e34b'), ObjectId('6726cc03fa90a11c6574e34c'), ObjectId('6726cc04fa90a11c6574e34d'), ObjectId('6726cc04fa90a11c6574e34e'), ObjectId('6726cc05fa90a11c6574e34f'), ObjectId('6726cc06fa90a11c6574e350'), ObjectId('6726cc07fa90a11c6574e351'), ObjectId('6726cc08fa90a11c6574e352'), ObjectId('6726cc09fa90a11c6574e353'), ObjectId('6726cc09fa90a11c6574e354')]\n"
     ]
    }
   ],
   "source": [
    "together_api_key = os.getenv('TOGETHER_API')\n",
    "\n",
    "\n",
    "#code for embedding\n",
    "embedding_model_string = 'WhereIsAI/UAE-Large-V1' # model API string from Together.\n",
    "\n",
    "def generate_embedding(input_texts: List[str], model_api_string: str) -> List[List[float]]:\n",
    "  together_client = Together(api_key=together_api_key)\n",
    "  outputs = together_client.embeddings.create(\n",
    "      input=input_texts,\n",
    "      model=model_api_string,\n",
    "  )\n",
    "  return [x.embedding for x in outputs.data]\n",
    "\n",
    "insertObjectIds = []\n",
    "\n",
    "# Set up MongoDB client\n",
    "uri = os.getenv('DATABASE_URI')\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client['Instagram']\n",
    "collection = db[\"Events\"]\n",
    "\n",
    "# Remove all documents with 'account': \"WUSA\"\n",
    "try:\n",
    "    result = collection.delete_many({'account': \"WUSA\"})\n",
    "    print(f\"Documents removed: {result.deleted_count}\")\n",
    "except errors.PyMongoError as e:\n",
    "    print(f\"Error deleting documents: {e}\")\n",
    "\n",
    "# Check and remove '_id' column if present\n",
    "if '_id' in wusaDf.columns:\n",
    "    print(\"DataFrame contains an '_id' column. It will be removed to prevent duplication.\")\n",
    "    wusaDf = wusaDf.drop(columns=['_id'])\n",
    "\n",
    "for index, row in wusaDf.iterrows():\n",
    "    # Construct the info string\n",
    "    info = f'\"id\": \"{int(index)}\"|* \"account\": \"{row[\"account\"]}\"|* \"date\": \"{row[\"date\"]}\"|* \"caption\": \"{row[\"caption\"]}\"|*'\n",
    "    embeddedtext = ',\\n'.join(x for x in info.replace('\\n','\\\\n').split('|*')) \n",
    "\n",
    "    # Create the document dictionary\n",
    "    row_dict = {column: row[column] for column in wusaDf.columns.tolist()}\n",
    "    \n",
    "    # Add the embedded field\n",
    "    row_dict[\"embedded\"] = generate_embedding([embeddedtext], embedding_model_string)\n",
    "    \n",
    "    # Remove '_id' if present to let MongoDB generate it\n",
    "    row_dict.pop('_id', None)\n",
    "    \n",
    "    try:\n",
    "        result = collection.insert_one(row_dict)\n",
    "        print(f\"Inserted document ID: {result.inserted_id}\")\n",
    "        insertObjectIds.append(result.inserted_id)\n",
    "    except errors.DuplicateKeyError as e:\n",
    "        print(f\"DuplicateKeyError: {e}. Document skipped.\")\n",
    "    except errors.PyMongoError as e:\n",
    "        print(f\"An error occurred: {e}. Document skipped.\")\n",
    "    \n",
    "    time.sleep(0.5)  # Adjust or remove delay as needed\n",
    "\n",
    "# Optionally, print all inserted ObjectIds\n",
    "print(f\"All inserted document IDs: {insertObjectIds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "No\n",
      "Yes\n",
      "No\n",
      "No\n",
      "Yes\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "Yes\n",
      "No\n",
      "Yes\n",
      "Yes\n",
      "No\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "#Validating if it is an event\n",
    "load_dotenv()\n",
    "togetherAPI = os.getenv('TOGETHER_API')\n",
    "client = Together(api_key=togetherAPI)\n",
    "\n",
    "postsDf = pd.read_csv(instagram_data_filepath).replace('\"','', regex=True)\n",
    "postsDf[\"is_event\"] = pd.NA\n",
    "postsDf[\"processed_json\"]=pd.NA\n",
    "\n",
    "def check_string(input_string):\n",
    "    if any(word in input_string for word in ['yes', 'Yes', 'True', 'true']):\n",
    "        return True\n",
    "    elif any(word in input_string for word in ['no', 'No', 'False', 'false']):\n",
    "        return False\n",
    "    else:\n",
    "        return False  # This handles cases where none of the words are found\n",
    "\n",
    "\n",
    "cnt=0\n",
    "for index, row in postsDf.iterrows():\n",
    "    currentjson = f\"'account': '{row['account']}'; 'caption': '{row['caption']}'; 'photo_caption': '{row['accessibility_caption']}; 'date_posted_on_instagram: {row['date']}'\"\n",
    "    postsDf.at[index, \"processed_json\"] = currentjson\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f'Does the following instagram post contain a club event with a specified time. RETURN Yes or No only: {currentjson}'}],\n",
    "        max_tokens=2\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    is_event = check_string(response.choices[0].message.content)\n",
    "    postsDf.at[index, \"is_event\"] = is_event\n",
    "    time.sleep(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to Aid in LLM JSON data extraction\n",
    "\n",
    "\n",
    "client = Together(api_key=togetherAPI)\n",
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Unicode ranges for emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "class Category(Enum):\n",
    "    TECH = auto()\n",
    "    DESIGN = auto()\n",
    "    SOCIAL = auto()\n",
    "    ENTERTAINMENT = auto()\n",
    "    CULTURE = auto()\n",
    "    SPORTS = auto()\n",
    "    NETWORKING = auto()\n",
    "    GAMING = auto()\n",
    "\n",
    "class Event(BaseModel):\n",
    "    is_event: bool = Field(description=\"Whether the post contains an event\")\n",
    "    event_name: str = Field(description=\"The Name of the Event\")\n",
    "    event_description: str = Field(description='Concise 20 word summary of the event without time or location')\n",
    "    event_categories: list[str] = Field(description='Categorize the Event into at least one or more of the following: TECH, DESIGN, SOCIAL, MUSIC, CULTURE, SPORTS, NETWORK, GAMING')\n",
    "    start_time: str = Field(description=\"The Start time of Event in the format: yyyy-mm-ddTHH:MM:SS+00:00\")\n",
    "    end_time: str = Field(description=\"The End time of Event in the format: yyyy-mm-ddTHH:MM:SS+00:00\")\n",
    "    location: str = Field(description= \"The location of event\")\n",
    "\n",
    "def return_event_details(inputJson : str):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    model = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    response_format={\"type\": \"json_object\", \"schema\": Event.model_json_schema()},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": basePrompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\n\\n Input \" + remove_emojis(inputJson) + \"\\n\\n\" + \"Output\",\n",
    "        },\n",
    "    ])\n",
    "    \n",
    "    created_event = json.loads(chat_completion.choices[0].message.content)\n",
    "    return created_event\n",
    "\n",
    "def extract_details_with_error_handling(inputJson, index):\n",
    "        try: \n",
    "            created_event = return_event_details(inputJson)\n",
    "            return created_event\n",
    "        except Exception as err:\n",
    "            print(str(err))\n",
    "            return {'is_event': False, 'event_name': None, 'start_time': None, 'end_time': None, 'location': None}\n",
    "\n",
    "postsDf[\"event_details\"] = pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "\n",
    "def download_instagram_image(url, filepath):\n",
    "    try:\n",
    "        # Send a GET request to the Instagram post URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Attempt to find the high-resolution image URL\n",
    "        image_meta = soup.find('meta', property='og:image')\n",
    "        if image_meta and 'content' in image_meta.attrs:\n",
    "            image_url = image_meta['content']\n",
    "            \n",
    "            # Modify the image URL to try to get the full-resolution version\n",
    "            if 's150x150' in image_url:\n",
    "                image_url = image_url.replace('s150x150', 's1080x1080')\n",
    "\n",
    "            # Download the image\n",
    "            image_response = requests.get(image_url)\n",
    "            image_response.raise_for_status()\n",
    "\n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "            # Save the image directly with the provided filepath\n",
    "            with open(filepath, 'wb') as file:\n",
    "                file.write(image_response.content)\n",
    "\n",
    "            print(f\"Image saved successfully: {filepath}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Could not find the image URL in the Instagram post.\")\n",
    "            return False\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error accessing the Instagram post or downloading the image: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Collection' object is not callable. If you meant to call the 'create' method on a 'Collection' object it is failing because no such method exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m postsDf\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m postsDf\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_event\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m         event_details \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_event_details\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpostsDf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(index, event_details)\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m event_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m event_details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[19], line 42\u001b[0m, in \u001b[0;36mreturn_event_details\u001b[1;34m(inputJson)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreturn_event_details\u001b[39m(inputJson : \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     chat_completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEvent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasePrompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m Input \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mremove_emojis\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputJson\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     created_event \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(chat_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m created_event\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pymongo\\collection.py:3479\u001b[0m, in \u001b[0;36mCollection.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name:\n\u001b[0;32m   3473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3474\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not callable. If you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3475\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeant to call the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method on a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatabase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject it is failing because no such method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3477\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexists.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name\n\u001b[0;32m   3478\u001b[0m     )\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object is not callable. If you meant to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method on a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object it is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailing because no such method exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3483\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Collection' object is not callable. If you meant to call the 'create' method on a 'Collection' object it is failing because no such method exists."
     ]
    }
   ],
   "source": [
    "for index, row in postsDf.iterrows():\n",
    "    if postsDf.at[index, \"is_event\"]== True:\n",
    "        event_details = return_event_details(str(postsDf.at[index, \"processed_json\"]))\n",
    "        print(index, event_details)\n",
    "        if event_details[\"event_name\"] == None or event_details[\"start_time\"] == None or event_details[\"end_time\"] == None:\n",
    "            postsDf.at[index, \"is_event\"] = False\n",
    "            postsDf.at[index, \"event_details\"] = None\n",
    "        else:\n",
    "            postsDf.at[index, \"event_details\"] = event_details\n",
    "            imageurl = row[\"display_photo\"]\n",
    "            postID = row[\"url\"]\n",
    "            correcturl = f'https://www.instagram.com/p/{postID}/size=lg'\n",
    "            filepath = image_filepath + postID + \".jpg\"\n",
    "            download_instagram_image(correcturl, filepath)\n",
    "    else: print(index, \"no event detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1731115800.0 1731123000.0\n",
      "1730766600.0 1730770200.0\n",
      "1731740400.0 1731826740.0\n",
      "12 Start failed 2024-07-xxT20:00:00+00:00\n",
      "1731740400.0 1731826740.0\n",
      "1572913800.0 1572921000.0\n",
      "15 Start failed \n",
      "1572913800.0 1572921000.0\n",
      "Inserted document ID: 6726d06dfa90a11c6574e356\n",
      "Inserted document ID: 6726d06efa90a11c6574e357\n",
      "Inserted document ID: 6726d06ffa90a11c6574e358\n",
      "Inserted document ID: 6726d071fa90a11c6574e359\n"
     ]
    }
   ],
   "source": [
    "#RAG Processing\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "uri = os.getenv('DATABASE_URI')\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client['Instagram']\n",
    "collection = db[\"Events\"]\n",
    "\n",
    "#time conversion and edit formats\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "postsDf.reset_index(drop=True)\n",
    "postsDf = postsDf.fillna(value=\"None\")\n",
    "postsDf.drop(postsDf.columns[postsDf.columns.str.contains(\n",
    "    'unnamed', case=False)], axis=1, inplace=True)\n",
    "\n",
    "for index, row in postsDf.iterrows():\n",
    "    if row[\"is_event\"] == True:\n",
    "      row_dict = row[\"event_details\"]\n",
    "      try:\n",
    "        conStart = datetime.fromisoformat(row_dict[\"start_time\"])\n",
    "        unixStart = time.mktime(conStart.timetuple()) \n",
    "        try:\n",
    "          conEnd = datetime.fromisoformat(row_dict[\"end_time\"])\n",
    "          unixEnd = time.mktime(conEnd.timetuple())\n",
    "        except:\n",
    "          unixEnd = None\n",
    "        row_dict[\"start_time\"]=unixStart\n",
    "        row_dict[\"end_time\"]=unixEnd\n",
    "      except:\n",
    "        postsDf.at[index, \"is_event\"] = False\n",
    "        err = f'Start failed {row_dict[\"start_time\"]}'\n",
    "        print(index, err)\n",
    "      postsDf.at[index, \"event_details\"] = row_dict\n",
    "      print(unixStart,unixEnd)\n",
    "\n",
    "together_api_key = os.getenv('TOGETHER_API')\n",
    "\n",
    "\n",
    "#code for embedding\n",
    "embedding_model_string = 'WhereIsAI/UAE-Large-V1' # model API string from Together.\n",
    "\n",
    "def generate_embedding(input_texts: List[str], model_api_string: str) -> List[List[float]]:\n",
    "  together_client = Together(api_key=together_api_key)\n",
    "  outputs = together_client.embeddings.create(\n",
    "      input=input_texts,\n",
    "      model=model_api_string,\n",
    "  )\n",
    "  return [x.embedding for x in outputs.data]\n",
    "\n",
    "for index, row in postsDf.iterrows():\n",
    "    if row[\"is_event\"] == True:\n",
    "      row_dict = {}\n",
    "      for column in postsDf.columns.tolist():\n",
    "        if column in ['account','date','caption','accessibility_caption','url','likes','display_photo']:\n",
    "          row_dict[column] = row[column]\n",
    "      row_dict[\"embedded\"] = generate_embedding([row[\"processed_json\"]], embedding_model_string)  \n",
    "      row_dict[\"event_details\"] = row[\"event_details\"]\n",
    "      result = collection.insert_one(row_dict)\n",
    "      print(f\"Inserted document ID: {result.inserted_id}\")\n",
    "      time.sleep(1)\n",
    "\n",
    "#Updating Events.json\n",
    "\n",
    "def download_future_events_to_json(output_file):\n",
    "    # Get current Unix timestamp\n",
    "    current_timestamp = int(time.time())\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    load_dotenv()\n",
    "    uri = os.getenv('DATABASE_URI')\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    db = client['Instagram']\n",
    "    collection = db[\"Events\"]\n",
    "\n",
    "    # Query for future events\n",
    "    query = {}\n",
    "    future_events = list(collection.find(query))\n",
    "\n",
    "    # Convert ObjectId to string for JSON serialization\n",
    "    for event in future_events:\n",
    "        event['_id'] = str(event['_id'])\n",
    "\n",
    "    # Write to JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(future_events, f, indent=2)\n",
    "\n",
    "    # Close the MongoDB connection\n",
    "    client.close()\n",
    "\n",
    "    return future_events\n",
    "\n",
    "\n",
    "future_events = download_future_events_to_json(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
