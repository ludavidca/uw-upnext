{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\win_unicode_console\\__init__.py:31: RuntimeWarning: sys.stdin.encoding == 'utf-8', whereas sys.stdout.encoding == 'UTF-8', readline hook consumer may assume they are the same\n",
      "  readline_hook.enable(use_pyreadline=use_pyreadline)\n",
      "2024-09-02 14:34:27,671 - INFO - Scraping uwmuaythai\n",
      "2024-09-02 14:34:36,548 - INFO - Scraping techplusuw\n",
      "2024-09-02 14:34:44,476 - INFO - Scraping uwafow\n",
      "2024-09-02 14:34:50,731 - INFO - Scraping yourwusa\n",
      "2024-09-02 14:34:58,255 - INFO - Scraping uwaterloosc\n",
      "2024-09-02 14:35:04,747 - INFO - Scraping uwmidsun\n",
      "2024-09-02 14:35:12,050 - INFO - Scraping uwaterloodsc\n",
      "2024-09-02 14:35:20,926 - INFO - Scraping uwmcc\n",
      "2024-09-02 14:35:28,493 - INFO - Scraping watolink_uw\n",
      "2024-09-02 14:35:35,079 - INFO - Scraping uwhiphop\n",
      "2024-09-02 14:35:40,722 - INFO - Scraping uwaterloopm\n",
      "2024-09-02 14:35:47,211 - INFO - Scraping uwaterloocycling\n",
      "2024-09-02 14:35:53,566 - INFO - Scraping waterloo.frosh\n",
      "2024-09-02 14:36:00,173 - INFO - Scraping uwactsciclub\n",
      "2024-09-02 14:36:06,457 - INFO - Scraping uwcheeseclub\n",
      "2024-09-02 14:36:11,813 - INFO - Scraping socratica.info\n",
      "2024-09-02 14:36:18,050 - INFO - Scraping uwaterlooeng\n",
      "2024-09-02 14:36:24,763 - INFO - Scraping uwaterloo_ksa\n",
      "2024-09-02 14:36:31,522 - INFO - Scraping uwstatsclub\n",
      "2024-09-02 14:36:38,648 - INFO - Scraping electriummobility\n",
      "2024-09-02 14:36:46,716 - INFO - Scraping uw_ux\n",
      "2024-09-02 14:36:54,027 - INFO - Scraping uw_bmsa\n",
      "2024-09-02 14:37:00,602 - INFO - Scraping gdscwaterloo\n",
      "2024-09-02 14:37:06,492 - INFO - Scraping uw.dhamaka\n",
      "2024-09-02 14:37:20,690 - INFO - Scraping waterlooblockchain\n",
      "2024-09-02 14:37:27,385 - INFO - Scraping uwaterloobsa\n",
      "2024-09-02 14:37:33,478 - INFO - Scraping uwmcc\n",
      "2024-09-02 14:37:45,454 - INFO - Scraping uwengsoc\n",
      "2024-09-02 14:37:51,617 - INFO - Scraping uwmariokart\n",
      "2024-09-02 14:38:01,603 - INFO - Scraping uw_watsam\n",
      "2024-09-02 14:38:05,024 - ERROR - Error scraping uw_watsam (attempt 1/3): Redirected to login page. Use --login or --load-cookies.\n",
      "2024-09-02 14:38:05,026 - INFO - Retrying uw_watsam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HTTP redirect from https://i.instagram.com/api/v1/users/web_profile_info/?username=uw_watsam to https://i.instagram.com/accounts/login/?next=/api/v1/users/web_profile_info/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 14:38:17,467 - ERROR - Error scraping uw_watsam (attempt 2/3): Redirected to login page. Use --login or --load-cookies.\n",
      "2024-09-02 14:38:17,469 - INFO - Retrying uw_watsam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HTTP redirect from https://i.instagram.com/api/v1/users/web_profile_info/?username=uw_watsam to https://i.instagram.com/accounts/login/?next=/api/v1/users/web_profile_info/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 14:38:35,034 - INFO - Scraping uw.gsa\n",
      "2024-09-02 14:38:40,772 - INFO - Scraping uwmsa\n",
      "2024-09-02 14:38:47,727 - INFO - Scraping uwaterloopm\n",
      "2024-09-02 14:38:55,535 - INFO - Scraping uwhiphop\n",
      "2024-09-02 14:39:02,523 - INFO - Scraping uwcsclub\n",
      "2024-09-02 14:39:14,550 - INFO - Scraping uwstartups\n",
      "2024-09-02 14:39:20,864 - INFO - Scraping uwaterloottc\n",
      "2024-09-02 14:39:26,674 - INFO - Scraping itshera.co\n",
      "2024-09-02 14:39:32,038 - INFO - Scraping uwblueprint\n",
      "2024-09-02 14:39:40,131 - INFO - Scraping uwstreetdance\n",
      "2024-09-02 14:39:45,947 - INFO - Scraping uw.farmsa\n",
      "2024-09-02 14:39:51,279 - INFO - Scraping gdscwaterloo\n",
      "2024-09-02 14:39:56,654 - INFO - Scraping uwtsa\n",
      "2024-09-02 14:40:08,124 - INFO - Scraping uw_aviation\n",
      "2024-09-02 14:40:15,585 - INFO - Scraping uwawscloud\n",
      "2024-09-02 14:40:21,000 - INFO - Scraping uwbeautyclub\n",
      "2024-09-02 14:40:28,178 - INFO - Scraping wat.street\n",
      "2024-09-02 14:40:33,772 - INFO - Scraping uwteaclub\n",
      "2024-09-02 14:40:39,410 - INFO - Scraping waterloo.ai\n",
      "2024-09-02 14:40:45,819 - INFO - Scraping uwrealitylabs\n",
      "2024-09-02 14:40:51,103 - INFO - Scraping uw_urc\n",
      "2024-09-02 14:40:56,620 - INFO - Scraping uw.movie.watchers\n",
      "JSON Query to api/v1/users/web_profile_info/?username=uw.movie.watchers: HTTPSConnectionPool(host='i.instagram.com', port=443): Max retries exceeded with url: /api/v1/users/web_profile_info/?username=uw.movie.watchers (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001355292E480>: Failed to establish a new connection: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions')) [retrying; skip with ^C]\n",
      "JSON Query to api/v1/users/web_profile_info/?username=uw.movie.watchers: HTTPSConnectionPool(host='i.instagram.com', port=443): Max retries exceeded with url: /api/v1/users/web_profile_info/?username=uw.movie.watchers (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000013552F3EA20>: Failed to establish a new connection: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions')) [retrying; skip with ^C]\n",
      "2024-09-02 14:41:00,268 - ERROR - Error scraping uw.movie.watchers (attempt 1/3): JSON Query to api/v1/users/web_profile_info/?username=uw.movie.watchers: HTTPSConnectionPool(host='i.instagram.com', port=443): Max retries exceeded with url: /api/v1/users/web_profile_info/?username=uw.movie.watchers (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000013552F3EAB0>: Failed to resolve 'i.instagram.com' ([Errno 11004] getaddrinfo failed)\"))\n",
      "2024-09-02 14:41:00,270 - INFO - Retrying uw.movie.watchers...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "def scrape_handle(L, handle, cutoffdate):\n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    posts_data = []\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            profile = instaloader.Profile.from_username(L.context, handle)\n",
    "            for post in profile.get_posts():\n",
    "                if post.date > cutoffdate:\n",
    "                    photo_caption = post.accessibility_caption if post.accessibility_caption is not None else \"\"\n",
    "                    caption = post.caption if post.caption is not None else \"\"\n",
    "                    posts_data.append({\n",
    "                        'url': post.shortcode,\n",
    "                        'likes': post.likes,\n",
    "                        'display_photo': post.url,\n",
    "                        'account': handle.replace('\\\"','\\\\\\\"'),\n",
    "                        'date': post.date,\n",
    "                        'caption': caption.replace(\"\\n\",\"\"),\n",
    "                        'accessibility_caption': photo_caption.replace(\"\\n\",\"\"),\n",
    "                    })\n",
    "                else:\n",
    "                    break\n",
    "            return posts_data\n",
    "        except (instaloader.exceptions.InstaloaderException, RequestException) as e:\n",
    "            retry_count += 1\n",
    "            logging.error(f\"Error scraping {handle} (attempt {retry_count}/{max_retries}): {str(e)}\")\n",
    "            if retry_count < max_retries:\n",
    "                logging.info(f\"Retrying {handle}...\")\n",
    "                time.sleep(10)  # Wait for 5 seconds before retrying\n",
    "            else:\n",
    "                logging.error(f\"Max retries reached for {handle}. Moving to next handle.\")\n",
    "    return []\n",
    "\n",
    "def scrape_instagram():\n",
    "    cutoffdate = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "    handles = ['uwengsoc','uwcsa','uw_ux','uwblueprint','uwaterlooeng','uwaterloottc','uwaterloodsc','uwaterloopm','uwmcc','gdscwaterloo','uwsmileclub','socratica.info','yourwusa','wataiteam','uwawscloud','techplusuw','itshera.co','uwstartups','electriummobility','uwhiphop','uwaterloo_ksa','uw_aviation','uwaterloopm','uwmcc','uwmsa','gdscwaterloo','waterloo_ultimate','uwcheeseclub','uwstreetdance','uwmidsun','watolink_uw','uwaterlooeng','uwpokerclub','uwaterloocycling','uwaterloobsa','uw_phys_club','uw.gsa','uwcsclub','uwfintech','uwaterloosc','uwactsciclub','uwstatsclub','waterloo.frosh','wat.street','waterlooblockchain','waterloo.ai','uw_watsam','uwrealitylabs','uwafow','uwmuaythai','uw.farmsa','uw_bmsa','uwtsa','uwmariokart','uwhiphop','uw.movie.watchers','uwbeautyclub','uwteaclub','uw_urc','uw.dhamaka']\n",
    "    random.shuffle(handles)\n",
    "    postsDf = pd.DataFrame()\n",
    "\n",
    "    L = instaloader.Instaloader()\n",
    "    \n",
    "    for handle in handles:\n",
    "        logging.info(f\"Scraping {handle}\")\n",
    "        handle_data = scrape_handle(L, handle, cutoffdate)\n",
    "        if handle_data:\n",
    "            postsDf = pd.concat([postsDf, pd.DataFrame(handle_data)], ignore_index=True)\n",
    "        time.sleep(random.randrange(4,5))  # Delay between handles to avoid rate limiting\n",
    "\n",
    "    return postsDf\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    try:\n",
    "        result = scrape_instagram()\n",
    "        print(result)\n",
    "        logging.info(\"Scraping completed successfully.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    postsDf = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsDf.reset_index(drop=True) \n",
    "postsDf.to_csv(\"instagram_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary Screening to determine if posts contains event or not\n",
    "\n",
    "from together import Together\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "togetherAPI = os.getenv('TOGETHER_API')\n",
    "client = Together(api_key=togetherAPI)\n",
    "\n",
    "postsDf = pd.read_csv(\"instagram_raw.csv\").replace('\"','', regex=True)\n",
    "postsDf[\"is_event\"] = pd.NA\n",
    "postsDf[\"processed_json\"]=pd.NA\n",
    "\n",
    "def check_string(input_string):\n",
    "    if any(word in input_string for word in ['yes', 'Yes', 'True', 'true']):\n",
    "        return True\n",
    "    elif any(word in input_string for word in ['no', 'No', 'False', 'false']):\n",
    "        return False\n",
    "    else:\n",
    "        return False  # This handles cases where none of the words are found\n",
    "\n",
    "\n",
    "cnt=0\n",
    "for index, row in postsDf.iterrows():\n",
    "    currentjson = f\"'account': '{row['account']}'; 'caption': '{row['caption']}'; 'photo_caption': '{row['accessibility_caption']}'\"\n",
    "    postsDf.at[index, \"processed_json\"] = currentjson\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f'Does the following instagram post contain a club event with a specified time. RETURN Yes or No: {currentjson}'}],\n",
    "        max_tokens=2\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    is_event = check_string(response.choices[0].message.content)\n",
    "    postsDf.at[index, \"is_event\"] = is_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsDf.to_csv(\"preliminaryProcessedInformation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from together import Together\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "from enum import Enum, auto\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "togetherAPI = os.getenv('TOGETHER_API')\n",
    "client = Together(api_key=togetherAPI)\n",
    "\n",
    "basePrompt = open(\"C:/Users/david/Desktop/uw-upnext/WebScraper/basePrompt.in\",\"r\", encoding = \"utf-8\").read()\n",
    "\n",
    "postsDf = pd.read_csv(\"C:/Users/david/Desktop/uw-upnext/WebScraper/preliminaryProcessedInformation.csv\")\n",
    "\n",
    "basePrompt = open(\"basePrompt.in\",\"r\", encoding = \"utf-8\").read()\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # Unicode ranges for emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "class Category(Enum):\n",
    "    TECH = auto()\n",
    "    DESIGN = auto()\n",
    "    SOCIAL = auto()\n",
    "    ENTERTAINMENT = auto()\n",
    "    CULTURE = auto()\n",
    "    SPORTS = auto()\n",
    "    NETWORKING = auto()\n",
    "    GAMING = auto()\n",
    "\n",
    "class Event(BaseModel):\n",
    "    is_event: bool = Field(description=\"Whether the post contains an event\")\n",
    "    event_name: str = Field(description=\"The Name of the Event\")\n",
    "    event_description: str = Field(description='Concise 20 word summary of the event without time or location')\n",
    "    event_categories: list[str] = Field(description='Categorize the Event into at least one or more of the following: TECH, DESIGN, SOCIAL, MUSIC, CULTURE, SPORTS, NETWORK, GAMING')\n",
    "    start_time: str = Field(description=\"The Start time of Event in the format: yyyy-mm-ddTHH:MM:SS+00:00\")\n",
    "    end_time: str = Field(description=\"The End time of Event in the format: yyyy-mm-ddTHH:MM:SS+00:00\")\n",
    "    location: str = Field(description= \"The location of event\")\n",
    "\n",
    "def return_event_details(inputJson : str):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    model = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    response_format={\"type\": \"json_object\", \"schema\": Event.model_json_schema()},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": basePrompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\\n\\n Input \" + remove_emojis(inputJson) + \"\\n\\n\" + \"Output\",\n",
    "        },\n",
    "    ])\n",
    "    \n",
    "    created_event = json.loads(chat_completion.choices[0].message.content)\n",
    "    return created_event\n",
    "\n",
    "def extract_details_with_error_handling(inputJson, index):\n",
    "        try: \n",
    "            created_event = return_event_details(inputJson)\n",
    "            return created_event\n",
    "        except Exception as err:\n",
    "            print(str(err))\n",
    "            return {'is_event': False, 'event_name': None, 'start_time': None, 'end_time': None, 'location': None}\n",
    "    \n",
    "# print(extract_details_with_error_handling(processedjson[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsDf = pd.read_csv(\"preliminaryProcessedInformation.csv\")\n",
    "\n",
    "postsDf[\"event_details\"] = pd.NA\n",
    "\n",
    "\n",
    "for index, row in postsDf.iterrows():\n",
    "    if postsDf.at[index, \"is_event\"]== True:\n",
    "        event_details = return_event_details(str(postsDf.at[index, \"processed_json\"]))\n",
    "        print(index, event_details)\n",
    "        if event_details[\"event_name\"] == None or event_details[\"start_time\"] == None or event_details[\"end_time\"] == None:\n",
    "            postsDf.at[index, \"is_event\"] = False\n",
    "            postsDf.at[index, \"event_details\"] = None\n",
    "        else:\n",
    "            postsDf.at[index, \"event_details\"] = event_details\n",
    "    else: print(index, \"no event detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsDf.reset_index(drop=True) \n",
    "postsDf.to_csv(\"information_for_mongo.csv\")\n",
    "\n",
    "print(postsDf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
